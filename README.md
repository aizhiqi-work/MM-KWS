# MM-KWS: Multi-modal Prompts for Multilingual User-defined Keyword Spotting（Updating）

### Note
1. Code for the paper 'MM-KWS: Multi-modal Prompts for Multilingual User-defined Keyword Spotting', Interspeech 2024 accepted
2. Arxiv: <a>https://arxiv.org/pdf/2406.07310</a>
3. The code-version1
4. WenetPrase hardneg-data & Libriphrase hardneg-data
5. DataAug data(todo)

---
### Performance
#### 1.1 Performance on LibriPhrase
   <img src=https://github.com/aizhiqi-work/MM-KWS/assets/98506724/a893c8b5-7104-4044-87ed-85d418e33f0b width=40% />

#### 1.2 Performance on WenetPhrase
   <img src=https://github.com/aizhiqi-work/MM-KWS/assets/98506724/450d14f3-9621-44cb-8156-9f4e80b34ab9 width=40% />
   
#### 2.Zero-shot performance on Speech Command
   <img src=https://github.com/aizhiqi-work/MM-KWS/assets/98506724/5736d986-ddd0-4059-8897-2bcc47942f79 width=40% />

#### 3. Few-shot performance on wake-up word(snips)
   Note: I wrote about the wake word experiment for my master thesis, which was deleted from the Interspeech manuscript due to space limit.
   
   <img src=https://github.com/aizhiqi-work/MM-KWS/assets/98506724/24fc52e9-89bd-40c8-9f98-caec343a1d84 width=40% />
   
---




