# MM-KWS: Multi-modal Prompts for Multilingual User-defined Keyword Spotting（Updating）

### Note
---
1. Code for the paper 'MM-KWS: Multi-modal Prompts for Multilingual User-defined Keyword Spotting', Interspeech 2024 accepted
2. Arxiv: <a>https://arxiv.org/pdf/2406.07310</a>
4. The code will be released in this month, I'm busy with my masters thesis

### Dataset
---
1. LibriPhrase:
2. WenetPhrase:
3. Speech Command:

### Performance
---
1. LibriPhrase
![image](https://github.com/aizhiqi-work/MM-KWS/assets/98506724/a893c8b5-7104-4044-87ed-85d418e33f0b)
2. WenetPhrase
![image](https://github.com/aizhiqi-work/MM-KWS/assets/98506724/450d14f3-9621-44cb-8156-9f4e80b34ab9)
3. Speech Command
![image](https://github.com/aizhiqi-work/MM-KWS/assets/98506724/5736d986-ddd0-4059-8897-2bcc47942f79)
4. other(snips), I wrote about the wake word experiment for my big thesis, which was deleted from the Interspeech manuscript due to space issues.
![image](https://github.com/aizhiqi-work/MM-KWS/assets/98506724/24fc52e9-89bd-40c8-9f98-caec343a1d84)




